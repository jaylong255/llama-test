# llama-test
This is an attempt to get a Llama 3 model running on an AMD/Radeon machine, preferably with a Langchain sort of interface like Private GPT or something.
